% !TEX root = ../doc.tex

\section{Discussion}

\subsection{Challenges and limitations}
\st{Lorem ipsum.}

\subsubsection*{Identification of features}
The basic question that arose in the process of identifying the features was: "What is counted as a feature? As mentioned above, the identification of features presented some challenges. The first challenge was the filtering out of "header features", which are used in some programming paradigms to include header files in the source code. However, these header features do not create variability in the code, so they are undesirable. Most of these header features were identifiable by their assigned names, which had a \texttt{\_h\_}. This way they could be quickly identified and filtered out using regular expressions. However, it is possible that in some software projects the header features are not explicitly identified by their names. This makes it difficult to identify them, for example by manually viewing the contexts of the features in the source code. In this case, however, this would be very time-consuming due to the large number of features and was therefore not performed. The removal of the recognizable header features showed that a considerable part of the previously identified features was undesirable. This method therefore proved to be effective. A solution that could contribute to the above problem would be a tool for parsing source code to correctly identify features by means of automated analysis of the context of the feature. This would also detect the "wrong" features mentioned above. Such a tool does not exist at the moment. Available feature identification tools use a similar approach as used in this thesis (regular expressions).

\subsubsection*{Integration of the reference to features}
As mentioned above, the reference to the features is based on the underlying files. Therefore the diffs of the modified files were analyzed. Thus, a feature is considered relevant if it is mentioned in a diff. However, it may also be the case that the feature code it contains was not involved in the change described in the diff, but was only mentioned in the part of the diff referred to as "hunk". This denotes an overhang of the actual context of the described changes in the form of additional lines of code that follow this change. Thus, there is no "in-depth" analysis of the source code. However, this approach was also chosen by the scientific work underlying this paper \cite{Queiroz2016}. Also, the metrics of the features are calculated based on the metadata of the underlying files. Thus an over-approximation takes place.

\subsubsection*{Heuristic for identifying corrective Commits}
The heuristic for detecting corrective commits was changed during the course of the work. First, the entire commit message was analyzed for the presence of the keywords. However, this resulted in some commits being incorrectly identified as corrective. The reason for this was that the commit messages in some of the software projects used were very large in word count. These messages mentioned all the changes made by the commits, without exception. However, most of these changes were irrelevant for this purpose. It was found that the main statement or reason for the commit was in the first line of the commit message. The heuristics were then adjusted accordingly. A sample of corrective commits before and after the heuristic adjustment showed that the change caused irrelevant corrective commits to be removed.

\subsubsection*{Imprecision of the SZZ-Algorithm}

A limitation, which was established in the course of the creation of the data set through literature research, refers to the SZZ algorithm. This was used to identify commits that introduced bugs based on the commit hashes of the corrective commits. Analysis of the algorithm revealed that currently available implementations, and thus those of the Python tool PyDriller, can identify only about 69\% of the actual number of bug-introducing commits that exist \cite{Wen2019}. In addition, about 64\% of the identified commits were found to be incorrectly identified \cite{Wen2019}. The algorithm is therefore considered imprecise \cite{Wen2019}. The reasoning behind this is as follows:

\begin{quotation}
The reason is that the implicit assumptions of the SZZ algorithm
are violated by the insufficient file coverage and statement direct
coverage between bug-inducing and bug-fixing commits. - \cite{Wen2019}
\end{quotation}

Furthermore, the authors of the study found in tests conducted by themselves that the results of eight out of ten earlier studies were significantly influenced by the imprecise algorithm \cite{Wen2019}. This may therefore also apply to this work. However, there is currently no alternative method for identifying bug-introducing commits. Should a new method or an improved version of the SZZ algorithm be published, it would be a good idea to repeat the main steps of this work, taking the new method into account, to compare it with the results presented here in order to highlight the influences of the SZZ algorithm.