\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\babel@toc {ngerman}{}
\babel@toc {ngerman}{}
\babel@toc {ngerman}{}
\babel@toc {ngerman}{}
\babel@toc {ngerman}{}
\babel@toc {ngerman}{}
\babel@toc {ngerman}{}
\babel@toc {ngerman}{}
\babel@toc {english}{}
\babel@toc {ngerman}{}
\babel@toc {ngerman}{}
\babel@toc {ngerman}{}
\babel@toc {english}{}
\babel@toc {ngerman}{}
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {1.1}{\ignorespaces Generierung von Software-Produktlinien nach \cite {Thuem2014}\relax }}{4}{figure.caption.11}%
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {1.2}{\ignorespaces CRISP-DM Prozessmodells nach \cite {Chapman2000}\relax }}{6}{figure.caption.12}%
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {1.3}{\ignorespaces Phasen des CRISP-DM Prozessmodells nach \cite {Chapman2000} mit Zuordnung der Arbeitsphasen\relax }}{6}{figure.caption.13}%
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {1.4}{\ignorespaces Zeitlicher Ablaufplan der Arbeit als Gantt-Chart\relax }}{9}{figure.caption.19}%
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.1}{\ignorespaces Allgemeiner Prozess des überwachten Machine Learnings dargestellt anhand eines Beispiels (vereinfacht)\relax }}{12}{figure.caption.21}%
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.2}{\ignorespaces Angewendeter Prozess zur Durchführung der Klassfikation nach \cite {Ceylan2006}\relax }}{12}{figure.caption.22}%
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.3}{\ignorespaces Teil 1: Featurebasierter Prozess des überwachten Machine Learnings nach \cite {Queiroz2016}\relax }}{13}{figure.caption.23}%
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.4}{\ignorespaces Teil 2: Featurebasierter Prozess des überwachten Machine Learnings nach \cite {Queiroz2016}\relax }}{14}{figure.caption.25}%
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.5}{\ignorespaces Teil 3: Featurebasierter Prozess des überwachten Machine Learnings nach \cite {Queiroz2016}\relax }}{14}{figure.caption.26}%
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.1}{\ignorespaces Übersicht zur Gliederung des dritten Kapitels\relax }}{15}{figure.caption.28}%
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.2}{\ignorespaces Normalfall und unerwünschte Fälle bei der Identifizierung von Features\relax }}{18}{figure.caption.32}%
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.3}{\ignorespaces Ablauf der zweiten Phase des SZZ-Algorithmus (übersetzt, \cite {Borg2019})\relax }}{18}{figure.caption.33}%
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.4}{\ignorespaces Visualisierung zur Unterscheidung der Datensets\relax }}{20}{figure.caption.35}%
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.1}{\ignorespaces Grundsätzlicher Aufbau eines Decision Trees\relax }}{24}{figure.caption.42}%
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.2}{\ignorespaces Formel zur Berechnung der Euklidischen Distanz (n = Anzahl der Attribute)\relax }}{25}{figure.caption.44}%
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.3}{\ignorespaces Grundsätzlicher Aufbau eines KNN mit 4 Input-Neuronen, 5 Hidden-Neuronen und 2 Output-Neuronen\relax }}{26}{figure.caption.46}%
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.4}{\ignorespaces Satz von Bayes als Grundlage des Na\"{\i }ve-Bayes-Klassifikators\relax }}{26}{figure.caption.48}%
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.5}{\ignorespaces Vergleich der Accuracies je Klassifikator vor und nach der Anwendung des SMOTE-Algorithmus\relax }}{28}{figure.caption.52}%
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.6}{\ignorespaces Vergleich der Klassifikatoren und Werkzeuge im Hinblick auf ihre Accuracies\relax }}{29}{figure.caption.53}%
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {5.1}{\ignorespaces allgemeine Konfusionsmatrix\relax }}{32}{figure.caption.55}%
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {5.2}{\ignorespaces Vergleich der Accuracies zwischen den Datensets der scikit-Klassifikatoren\relax }}{34}{figure.caption.58}%
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {5.3}{\ignorespaces Vergleich der Accuracies zwischen den Werkzeugen der WEKA-Klassifikatoren\relax }}{35}{figure.caption.59}%
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {5.4}{\ignorespaces Übersicht der Accuracies der jeweilgen Klassifikatoren)\relax }}{36}{figure.caption.63}%
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
