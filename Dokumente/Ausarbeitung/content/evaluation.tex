% !TEX root = ../thesis.tex

\chapter{Evaluation}
\label{evaluation}

Dieses Kapitel dient der Evaluation der im vorangegangenen Kapitel erläuterten Klassifikationen. Dies geschieht durch verschiedene Evaluationsmetriken, welche in diesem Kapitel vorgestellt werden und auf Werten von sogenannten Konfusionsmatrizen basieren. Zudem umfasst dieses Kapitel eine Erläuterung von Herausforderungen und Limitationen, die im Laufe der Bearbeitung der Arbeit festgestellt worden sind. Abschließen wird dieses Kapitel ein Vergleich der Klassifikatoren zu einer klassischen dateibasierten Methode, welche aus der wissenschaftlichen Literatur entnommen wurde.
\\
\hrule

\section{Herausforderungen und Limitationen}

In diesem Abschnitt werden eine Reihe von Herausforderungen und Limitationen aufgezählt und erläutert, die im Rahmen der Erarbeitung auffällig wurden.

\subsection*{Identifikation von Features}

Die grundsätzliche Frage, die im Rahmen der Identifikation der Features aufkam, war: \glqq Was wird als Feature gezählt?\grqq. Wie bereits in \hyperref[construction]{Abschnitt 3.2} erwähnt wurde, barg die Identifikation der Features einige Herausforderungen. So gestaltete sich die erste Herausforderung in der Ausfilterung von \glqq Header-Features\grqq{}, die in einigen Programmierparadigmen verwendet werden, um Header-Dateien im Sourcecode einzubinden. Diese Header-Features erzeugen jedoch keine Variabilität im Code, sodass sie unerwünscht sind. Identifizierbar waren die meisten dieser Header-Features an ihren vergebenen Namen, welche ein \texttt{\_h\_} aufwiesen. Auf diesem Weg konnten sie mittels regulärer Ausdrücke schnell ermittelt und ausgefiltert werden. Es besteht jedoch auch die Möglichkeit, dass in einigen Softwareprojekten die Header-Features nicht explizit durch ihre Namensgebung kenntlich gemacht werden. Sie lassen sich somit nur schwer identifizieren, beispielsweise durch eine manuelle Sichtung der Kontexte der Features im Sourcecode. Dies wäre jedoch im vorliegenden Fall aufgrund der großen Menge an Features sehr zeitaufwändig und wurde aus diesem Grund nicht durchgeführt. Die Entfernung der erkennbaren Header-Features zeigte, dass ein erheblicher Teil der zuvor identifizierten Features unerwünscht war. Diese Methode erwies sich somit als effektiv.
Eine Lösung, die zu dem genannten Problem beitragen könnte, wäre ein Tool zum Parsen von Sourcecode zur korrekten Identifikation von Features mittels automatisierter Analyse des Kontextes des Features. So würden auch die erwähnten \glqq falschen\grqq{} Features ermittelt werden. Ein solches Tool existiert momentan jedoch nicht. Verfügbare Tools zur Identifikation von Features verwenden einen ähnlichen Ansatz, wie er in dieser Arbeit verwendet wurde (reguläre Ausdrücke).

\subsection*{Einbindung des Bezugs zu Features}
Wie in Kapitel 3 festgestellt werden konnte, basiert der Bezug zu den Features auf den ihnen zugrundeliegenden Dateien. Dazu wurden die Diffs der veränderten Dateien analysiert. Ein Feature gilt somit als relevant, wenn es in einem Diff Erwähnung findet. Es kann jedoch auch vorkommen, dass der enthaltene Featurecode nicht an der im Diff beschriebenen Veränderung beteiligt war. Es findet somit keine \glqq in-depth\grqq -Analyse des Sourcecodes statt. Dieser Weg wurde jedoch auch von der dieser Arbeit zugrundeliegenden wissenschaftlichen Arbeit gewählt \cite{Queiroz2016}. Ebenfalls werden die Metriken der Features auf Basis der Metadaten der zugrundeliegenden Dateien berechnet.

\subsection*{Heuristik zur Erkennung von korrektiven Commits}

Die Heuristik zur Erkennung von korrektiven Commits wurde im Verlauf der Erarbeitung der Arbeit geändert. Zunächst wurde die gesamte Commit-Nachricht auf das Vorhandensein der Schlagworte analysiert. Dies führte jedoch dazu, dass einige Commits fälschlicherweise als korrektiv identifiziert wurden. Der Grund dafür war, dass die Commit-Nachrichten in einigen der verwendeten Softwareprojekte sehr umfangreich in der Anzahl der Wörter waren. In diesen Nachrichten wurden ausnahmslos alle Veränderungen, die mit den Commits vorgenommen wurden, erwähnt. Dabei handelte es sich jedoch meist um für diesen Zweck irrelevante Veränderungen. Es wurde festgestellt, dass sich die Hauptaussage beziehungsweise der Hauptgrund des Commits in der ersten Zeile der Commit-Nachricht befindet. Die Heuristik wurde daraufhin dementsprechend angepasst. Eine Stichprobe von korrektiven Commits vor und nach der Anpassung der Heuristik zeigte, dass die Veränderung dazu führte, dass tatsächlich irrelevante korrektive Commits entfernt wurden.

\subsection*{Unpräzisiertheit des SZZ-Algorithmus}

Eine Limitation, die im Laufe der Erstellung des Datensets durch Literaturrecherchen festgestellt wurde, bezieht sich auf den SZZ-Algorithmus. Dieser wurde genutzt, um fehlereinführende Commits auf Basis der Commit-Hashes der korrektiven Commits zu identifizieren. Analysen des Algorithmus ergaben, dass momentan verfügbare Implementationen und somit auch die des verwendeten Python-Tools PyDriller lediglich etwa 69\% der tatsächlich existierenden fehlereinführenden Commits identifizieren können \cite{Wen2019}. Darüber hinaus wurde herausgefunden, dass etwa 64\% der identifizierten Commits falsch ermittelt wurden \cite{Wen2019}. Der Algorithmus gilt somit als unpräzise \cite{Wen2019}. Die Begründung dafür lautet wie folgt:

\begin{quotation}
The reason is that the implicit assumptions of the SZZ algorithm
are violated by the insufficient file coverage and statement direct
coverage between bug-inducing and bug-fixing commits. - \cite{Wen2019}
\medskip \\
\textit{Der Grund dafür ist, dass die impliziten Annahmen des SZZ-Algorithmus durch die unzureichende \glqq file coverage\grqq{} und die unzureichende \glqq statement direct
coverage\grqq{} der Aussage zwischen fehlereinführenden und korrektiven Commits verletzt werden.}
\end{quotation}

Ferner stellten die Autoren der Studie in eigenen durchgeführten Tests fest, dass die Ergebnisse von acht von zehn früheren Studien durch den unpräzisen Algorithmus signifikant beeinflusst wurden \cite{Wen2019}. Dies kann somit auch auf diese Arbeit zutreffen. Es existiert jedoch momentan keine alternative Methode zur Identifizierung von fehlereinführenden Commits. Sollte eine neue Methode oder eine verbesserte Version des SZZ-Algorithmus veröffentlicht werden, so würde es sich anbieten, die Hauptschritte dieser Arbeit unter Berücksichtigung der neuen Methode zu wiederholen, um sie mit den hier vorliegenden Ergebnissen zu vergleichen, um die Einflüsse des SZZ-Algorithmus herauszustellen.

\subsection*{xfig}
\label{xfig}
Im Rahmen der Identifizierung der korrektiven Commits wurde festgestellt, dass für das Softwareprojekt xfig keine Ergebnisse erzielt werden konnte. Folglich konnten somit auch keine fehlereinführenden Commits festgestellt werden. Zu sehen ist dies auch in \autoref{tab:tools-values2}. Der Grund für die fehlende Identifizierung der korrektiven Commits ist, dass die Commit-Nachrichten des Softwareprojekts keine der festgelegten Schlagworte enthalten. Sie bestehen lediglich aus der Angabe der mit dem Commit freigegebenen Releasenummer. Beispiele dafür sind:

\begin{itemize}
\setlength{\itemsep}{-2pt}
\item Commit \texttt{af30126616c5c5a8db3ba017dedbcbdf48fbc528}\\Nachricht: \texttt{xfig-3.2.7b}
\item Commit \texttt{a444a8ae7995dbfd2ebce4696ed2cca7ad33b6e1}\\Nachricht: \texttt{xfig-3.2.6.tar.xz}
\item Commit \texttt{f3706bcafe9049247eee1a88d64f9f8b4e98c076}\\Nachricht: \texttt{xfig.3.0.tar.gz}
\end{itemize}

Der Umstand, dass weder korrektive noch fehlereinführende Commits identifiziert wurden, führt dazu, dass jedes Feature und jede Datei automatisch und möglicherweise fälschlicherweise als \glqq fehlerfrei\grqq{} eingestuft werden. In Anbetracht dieser Tatsache wurde entschieden, xfig bei der Zusammenstellung der finalen Datensets nicht mit einzubinden.

\subsection*{Vorhersageziel}
commits, releases?
\textbf{absprechen mit Daniel ...}

\section{Evaluationsmetriken}
\label{eval-metrics}

Die zum Vergleich der Klassifikatoren erhobenen Evaluationmetriken entstammen dem Themengebiet des Information Retrieval und gelten als Standardmesswerte für ihren Einsatzzweck \cite{Sammut2017}. Die meisten dieser Metriken lassen sich anhand von Werten einer sogenannten Konfusionsmatrix berechnen und messen allesamt die Performanz der Vorhersagen von Klassifikatoren unter verschiedenen Betrachtungsweisen. Im Falle einer binären Klassifikation, wie in dieser Arbeit, besteht diese Matrix aus vier Gruppen, deren Werte angeben, ob der jeweilige Klassifikator ein Objekt korrekt oder falsch einer der beiden Zielklassen zuordnen konnte \cite{Sammut2017}. Im Zusammenhang mit solchen Matrizen werden die beiden Zielklassen \glqq positiv\grqq{} und \glqq negativ\grqq{} genannt. Für diese Arbeit werden die positive Klasse dem Label \glqq fehlerfrei\grqq und die negative Klasse dem Label \glqq defekt\grqq{} zugeordnet. Die Form einer allgemeinen Konfusionsmatrix ist in \autoref{fig:confu} dargestellt.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{images/Confusion}
    \caption{allgemeine Konfusionsmatrix\label{fig:confu}}
\end{figure}

Sowohl scitkit-learn als auch WEKA besitzen die Option, Konfisionsmatrizen zu den durchgeführten Tests der Klassifikatoren auszugeben. Anhand der Werte der Zuordnungen zu den zuvor genannten Gruppen wurden die folgenden Evaluationsmetriken berechnet: 

\begin{itemize}
\item Treffergenauigkeit (Accuracy)
\\Dieser Wert misst die Treffergenauigkeit der Vorhersagen des Klassifikators und gibt an, inwieweit dessen Vorhersagen mit der modellierten Realität übereinstimmen \cite{Sammut2017}. Die Formel zur Berechnung der Accuracy lautet:
\\\[Accuracy = \frac{TP+TN}{TP+TN+FP+FN}\]
Das Ergebnis der Berechnung ist ein prozentualer Wert. 100\% stellen damit die bestmögliche Accuracy dar.
\item Echt-Positiv-Rate / Trefferquote (TP-Rate / Recall)
\\Dieser Wert gibt den Anteil der korrekt als positiv gewerteten Vorhersagen sämtlicher als positiv gewerteter Vorhersagen an \cite{Alpaydin2010}. Die Formel zur Berechnung der TP-Rate bzw. des Recalls lautet:
\\\[TP-Rate = \frac{TP}{TP+FN}\]
Das Ergebnis der Berechnung ist ein prozentualer Wert. 100\% stellen damit die bestmögliche TP-Rate bzw. den bestmöglichen Recall dar. Beide Begriffe werden parallel für die Berechnung der gezeigten Formel verwendet.
\item Positiver Vorhersagewert (Precision)
\\ Dieser Wert gibt die Anzahl der positiven Vorhersagen an, die auch tatsächlich zur positiven Klasse gehören \cite{Sammut2017}. Die Formel zur Bestimmung der Precision lautet:
\\\[Precision = \frac{TP}{TP+FP}\]
Das Ergebnis der Berechnung ist ein prozentualer Wert. 100\% stellen damit die bestmögliche Precision dar.
\item F-Maß (F-Score)
\\ Dieser Wert berechnet das harmonische Mittel der Werte Precision und Recall und liegt somit zwischen diesen beiden Werten, jedoch näher am kleineren Wert \cite{Sammut2017}. Die Formel zur Berechnung des F-Scores lautet:
\\\[F-Score = \frac{2TP}{2TP+FP+FN}\]
Das Ergebnis der Berechnung ist ein prozentualer Wert. 100\% stellen damit den bestmöglichen F-Score dar.
\end{itemize}

\label{roc-def}
Darüber hinaus wurden die sogenannten ROC-Kurven (ROC curve) der einzelnen Klassifikatoren ermittelt. Diese Wahrscheinlichkeitskurven bzw. -graphen (ROC = Receiver Operating characteristic, Betriebsverhalten des Empfängers), beschreiben das Verhältnis zwischen der TP-Rate (y-Achse) und der FP-Rate (x-Achse) \cite{Sammut2017,Narkhede2018}. Die Falsch-Positiv-Rate (FP-Rate) gibt dabei den Anteil der fälschlicherweise als positiv gewerteten Vorhersagen an \cite{Alpaydin2010}. Sie wird mittels der folgenden Formel berechnet:
\\\[FP-Rate = \frac{FP}{FP+TN}\]

Wie bei allen Metriken ist das Ergebnis der FP-Rate ein prozentualer Wert, der bestenfalls möglichst gering ausfallen sollte. Sowohl die TP-Rate als auch die FP-Rate geben nur singuläre Werte an, aus welchen sich keine Graphen herleiten lassen. Jeder Klassifikator errechnet jedoch im Rahmen der Vorhersage eines Datensatzes Wahrscheinlichkeiten, die die Zugehörigkeit zu den Werten der Zielklasse darstellen \cite{KNIMETV2019}. In der Regel wird ein Datenpunkt der positiven Klasse zugeordnet, wenn die Wahrscheinlichkeit einen Schwellenwert von 0,5 übersteigt - Datenpunkte, die diesen Schwellenwert unterschreiten werden wiederum der negativen Klasse zugeordnet \cite{KNIMETV2019}. Wird der Schwellenwert erhöht, so werden weniger Datenpunkte der positiven Klasse zugeordnet, wohingegen im Falle einer Absenkung des Schwellenwertes mehr Datenpunkte der positiven Klasse zugeordnet werden \cite{KNIMETV2019}. Für die Erstellung der ROC-Kurven werden somit die Werte der TP-Rate und der FP-Rate unter der Berücksichtigung der Schwellenwerte im Bereich von 0,0 bis 1,0 gegenübergestellt.

Eine weitere Metrik, die in Verbindung mit der ROC-Kurve auftritt, ist der ROC-Bereich (ROC area). Dieser Wert, der anhand der ROC-Kurve berechnet wird und auch AUC-Bereich (AUC = Area Under Curve, Bereich unter der Kurve) genannt wird, gibt an, in wieweit ein Klassifikator in der Lage ist, zwischen den Werten der Zielklassen zu unterscheiden \cite{Narkhede2018}. Je höher dieser Wert ist (1,0 ist das Maximum), desto besser trifft der Klassifikator korrekte Vorhersagen \cite{Narkhede2018}.

Am Beispiel des Schwellenwertes 0,5 wird nun die Interpretation der ROC-Kurve und des ROC-Bereiches vorgenommen. Unterstützt wird dies durch grafische Beispiele, die in \autoref{fig:curves} gezeigt werden. Der Idealfall ist in den (a) und (b) dargestellt. Die Wahrscheinlichkeitskurven der Zielklasse (a) weisen keine Überlappung auf. Die Werte der Zielklasse sind somit allesamt korrekt zugeordnet worden, sodass der Klassifikator korrekt zwischen diesen unterscheiden kann. Die diesem Fall entsprechende ROC-Kurve ist in (b) dargestellt. Der ROC-Bereich beträt in diesem Fall 1,0. Ein \glqq Normalfall\grqq{} ist in (c) und (d) dargestellt. Es ist in (c) zu erkennen, dass die Wahrscheinlichkeitskurven überlappen, sodass falsche Zuordnungen getroffen werden. Die entsprechende ROC-Kurve ist in (d) dargestellt. Der entsprechende ROC-Bereich beträgt im hier gezeigten Fall 0,7. Dies bedeutet, dass 70\% der Zuordnungen richtig getroffen werden. Verbessert werden können die Werte möglicherweise, wenn der Schwellenwert verändert wird. Der \glqq Worst Case\grqq, der bei der Performanzmessung mittels ROC-Kurven auftreten kann, ist in (e) und (f) dargestellt. In (e) ist zu erkennen, dass sich die Wahrscheinlichkeitskurven vollständig überlappen. Es findet somit eine willkürliche Zuordnung statt. Die zugehörige ROC-Kruve (f) entspricht einer Winkelhalbierenden. Ein weiterer Fehlerfall ist in (g) und (h) dargestellt. Die Wahrscheinlichkeitskurven (g) zeigen, dass die Zuordnungen gegenteilig erfolgen und somit der jeweils dem anderen Wert der Zielklasse falsch zugeordnet werden. Der entsprechende ROC-Bereich beträgt 0, da wie in (h) zu sehen ist, keine Fläche unter der Kurve vorhanden ist.

\begin{figure}[t]
  \centering
  \subfloat[][Idealfall]{\includegraphics[width=0.5\linewidth]{images/roc_ideal}}
  \subfloat[][Idealfall]{\includegraphics[width=0.25\linewidth]{images/roc_ideal_curve}}
  \qquad
  \subfloat[][\glqq Normalfall\grqq]{\includegraphics[width=0.5\linewidth]{images/roc_normal}}
  \subfloat[][\glqq Normalfall\grqq]{\includegraphics[width=0.25\linewidth]{images/roc_normal_curve}}
  \qquad
  \subfloat[][\glqq Worst Case\grqq]{\includegraphics[width=0.5\linewidth]{images/roc_worst}}
  \subfloat[][\glqq Worst Case\grqq]{\includegraphics[width=0.25\linewidth]{images/roc_worst_curve}}
  \qquad
  \subfloat[][Fehlerfall]{\includegraphics[width=0.5\linewidth]{images/roc_neg}}
  \subfloat[][Fehlerfall]{\includegraphics[width=0.25\linewidth]{images/roc_neg_curve}}
  \caption{Beispiel zur Interpretation der ROC-Kurve und des ROC-Bereiches (TPR = TP-Rate, FPR = FP-Rate, Threshold = Schwellenwert) \cite{Narkhede2018}
\label{fig:curves}}
\end{figure}

Alle vorgestellten Metriken werden automatisiert von den Werkzeugen scikit-learn und WEKA berechnet. Ferner besitzen beide Werkzeuge die Fähigkeit, ROC-Kurven mit den entsprechenden ROC-Werten auszugeben. Die im Rahmen der Evaluation der Klassifikatoren ermittelten Werte der Metriken sowie die ROC-Kurven und Werte der ROC-Bereiche werden im folgenden Abschnitt aufgeführt sowie innerhalb sowie zwischen den Datensets verglichen und interpretiert.

\fbox{\parbox{\linewidth}{RQ3a: WELCHE MITEINANDER VERGLEICHBAREN MERKMALE BESITZEN DIE KLASSIFIKATOREN?\medskip\\
Die Merkmale zum Vergleich stellen Evaluationsmetriken dar, welche auf Basis der Ergebnisse des Tests der Klassifikatoren errechnet werden und die Performanz der Vorhersagen auf verschiedene Weisen messen. Welche Metriken berechnet wurden beantwortet Forschungsfrage RQ3b.}}

\fbox{\parbox{\linewidth}{RQ3b: WELCHE METRIKEN KÖNNEN FÜR DEN VERGLEICH VERWENDET WERDEN?\medskip\\
Für den Vergleich der Klassifikatoren werden klassische Evaluationsmetriken verwendet, welche auf Basis von Konfusionsmatrizen berechnet werden. Die betrachteten Metriken lauten: Accuracy, TP-Rate, Precision und F-Score. Ebenfalls hinzugezogen werden die jeweiligen ROC-Kurven der Klassifikatoren inklusive der ROC-Bereiche. Diese Metriken stellen einen Standard für die Messung der Performanz der Vorhersagen von Klassifikatoren dar.}}

\section{Ergebnisse und Diskussion}
\label{results}

\subsection{Featurebasiertes Datenset}
\subsubsection*{Konfusionsmatrizen}

Als Basis der Ergebnisse der Evaluation der Klassifikatoren anhand der zuvor vorgestellten Metriken dienen die Konfusionsmatrizen. Die Matrizen des featurebasierten Datensets sind in \autoref{tab:mat-feat} aufgeführt, die Matrizen des dateibasierten Datensets können in \autoref{tab:mat-file} gefunden werden. Beide Tabellen sind in den Spalten in die beiden verwendeten Tools scikit-learn und WEKA unterteilt. Ferner bilden die Spalten die von den Klassifikatoren vorhergesagten Label ab, wohingegen die Zeilen die \glqq ground truth\grqq, also die Realität, abbilden. Außerdem werden die ermittelten Werte der jeweiligen Klassen in den Spalten \glqq Total\grqq zusammengezählt. Die für die Klassifikatoren verwendeten Abkürzungen können \autoref{tab:abbs} entnommen werden. Anzumerken ist, dass sich die Gesamtsummen der Werte aufgrund der jeweiligen Konfigurationen der Klassifikatoren (insbesondere durch die Wahl der Split-Ratios) unterscheiden.

\begin{table}[t]
\centering
\caption{Konfusionsmatrizen des featurebasierten Datensets}
\label{tab:mat-feat}
\resizebox{\linewidth}{!}{%
\begin{tabular}{|>{\hspace{0pt}}p{0.119\linewidth}>{\hspace{0pt}}p{0.362\linewidth}|>{\RaggedLeft\hspace{0pt}}p{0.156\linewidth}>{\RaggedLeft\hspace{0pt}}p{0.214\linewidth}>{\RaggedLeft\hspace{0pt}}p{0.139\linewidth}|} 
\cline{2-5}
\multicolumn{1}{>{\Centering\hspace{0pt}}p{0.119\linewidth}|}{} & \textbf{Ermittelt -\textgreater{}} & \textbf{defekt}  & \textbf{fehlerfrei}  & \textbf{total}  \\ 
\hline
\multirow{3}{0.119\linewidth}{\hspace{0pt}J48}                  & Realität defekt                    & 446              & 320                  & 766             \\
                                                                & Realität fehlerfrei                & 483              & 3.142                & 3.625           \\
                                                                & total                              & 929              & 3.462                & 4.391           \\ 
\hline
\multirow{3}{0.119\linewidth}{\hspace{0pt}KNN}                  & Realität defekt                    & 371              & 395                  & 766             \\
                                                                & Realität fehlerfrei                & 569              & 3.056                & 3.625           \\
                                                                & total                              & 940              & 3.451                & 4.391           \\ 
\hline
\multirow{3}{0.119\linewidth}{\hspace{0pt}LR}                   & Realität defekt                    & 309              & 457                  & 766             \\
                                                                & Realität fehlerfrei                & 1.020            & 2.605                & 3.625           \\
                                                                & total                              & 1.329            & 3.061                & 4.391           \\ 
\hline
\multirow{3}{0.119\linewidth}{\hspace{0pt}NB}                   & Realität defekt                    & 322              & 444                  & 766             \\
                                                                & Realität fehlerfrei                & 265              & 3.360                & 3.625           \\
                                                                & total                              & 587              & 3.804                & 4.391           \\ 
\hline
\multirow{3}{0.119\linewidth}{\hspace{0pt}NN}                   & Realität defekt                    & 327              & 439                  & 766             \\
                                                                & Realität fehlerfrei                & 1.019            & 2.606                & 3.625           \\
                                                                & total                              & 1.346            & 3.045                & 4.391           \\ 
\hline
\multirow{3}{0.119\linewidth}{\hspace{0pt}RF}                   & Realität defekt                    & 504              & 262                  & 766             \\
                                                                & Realität fehlerfrei                & 450              & 3.175                & 3.625           \\
                                                                & total                              & 954              & 3.437                & 4.391           \\ 
\hline
\multirow{3}{0.119\linewidth}{\hspace{0pt}SGD}                  & Realität defekt                    & 251              & 515                  & 766             \\
                                                                & Realität fehlerfrei                & 938              & 2.687                & 3.625           \\
                                                                & total                              & 1.189            & 3.202                & 4.391           \\ 
\hline
\multirow{3}{0.119\linewidth}{\hspace{0pt}SVM}                  & Realität defekt                    & 176              & 590                  & 766             \\
                                                                & Realität fehlerfrei                & 899              & 2.726                & 3.625           \\
                                                                & total                              & 1.075            & 3.316                & 4.391           \\
\hline
\end{tabular}
}
\end{table}

\subsubsection*{Accuracies}

Die erste Metrik, die verglichen wird, ist die Accuracy. Diese gibt die Treffergenauigkeit der Klassifikatoren an. Dargestellt werden die Ergebnisse zum besseren Vergleich als Balkendiagramme, aufgeteilt in die jeweiligen Datenset und verwendeten Tools. Das Diagramm des feturebasierten Datensets ist in \autoref{fig:final-feat} dargestellt. Der Vergleich des dateibasierten Datensets ist wiederum in \autoref{fig:final-file} abgebildet. Die konkreten Zahlenwerte können im \hyperref[appendix2]{Anhang} eingesehen werden.

\begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{images/final_feat}
    \caption{Vergleich der Accuracies des featurebasierten Datensets\label{fig:final-feat}}
\end{figure}

\subsubsection*{Weitere Evaluationsmetriken}

Dieser Abschnitt stellt die Ergebnisse der weiteren Evaluationsmetriken TP-Rate / Recall, FP-Rate, Precision und F-Score vor. Diese können in \autoref{tab:met-feat} für das featurebasierte Datenset und in \autoref{tab:met-file} für das dateibasierte Datenset eingesehen werden. Aufgeteilt werden die Ergebnisse nach verwendetem Tool sowie nach den Werten der Zielklasse \glqq fehlerfrei\grqq{} und \glqq defekt\grqq. Zudem wird das gewichtete Mittel angegeben. Dabei handelt es sich um den Mittelwert der Ergebnisse beider Werte der Zielklasse unter Einbezug der Anzahl der korrekten Vorhersagen je Wert. Es zeigt somit die Performanz aggregiert für beide Werte an und liegt im Idealfall bei 1,00. Die vollständigen Tabellen der Ergebnisse der Evaluation, inklusive einer weiteren Metrik, können im \hyperref[appendix3]{Anhang} gefunden werden.

\begin{table}[t]
\centering
\caption{Ergebnisse der Evaluationsmetriken des featurebasierten Datensets}
\label{tab:met-results-feat}
\resizebox{\linewidth}{!}{%
\begin{tabular}{|>{\hspace{0pt}}p{0.141\linewidth}>{\hspace{0pt}}p{0.245\linewidth}|>{\RaggedLeft\hspace{0pt}}p{0.185\linewidth}>{\RaggedLeft\hspace{0pt}}p{0.252\linewidth}>{\RaggedLeft\hspace{0pt}}p{0.168\linewidth}|} 
\cline{3-5}
\multicolumn{1}{>{\hspace{0pt}}p{0.141\linewidth}}{} &           & \textbf{defekt}  & \textbf{fehlerfrei}  & \textbf{gew.}\par{}\textbf{Mittel}   \\ 
\hline
\multirow{4}{0.141\linewidth}{\hspace{0pt}J48}       & TP-Rate   & 0,58             & 0,87                 & 0,82                                 \\
                                                     & FP-Rate   & 0,13             & 0,42                 & 0,37                                 \\
                                                     & Precision & 0,48             & 0,91                 & 0,83                                 \\
                                                     & F-Score   & 0,53             & 0,89                 & 0,82                                 \\ 
\hline
\multirow{4}{0.141\linewidth}{\hspace{0pt}KNN}       & TP-Rate   & 0,48             & 0,86                 & 0,79                                 \\
                                                     & FP-Rate   & 0,16             & 0,52                 & 0,45                                 \\
                                                     & Precision & 0,40             & 0,89                 & 0,80                                 \\
                                                     & F-Score   & 0,44             & 0,86                 & 0,79                                 \\ 
\hline
\multirow{4}{0.141\linewidth}{\hspace{0pt}LR}        & TP-Rate   & 0,40             & 0,72                 & 0,66                                 \\
                                                     & FP-Rate   & 0,28             & 0,60                 & 0,54                                 \\
                                                     & Precision & 0,23             & 0,85                 & 0,74                                 \\
                                                     & F-Score   & 0,30             & 0,78                 & 0,70                                 \\ 
\hline
\multirow{4}{0.141\linewidth}{\hspace{0pt}NB}        & TP-Rate   & 0,42             & 0,93                 & 0,84                                 \\
                                                     & FP-Rate   & 0,07             & 0,58                 & 0,49                                 \\
                                                     & Precision & 0,55             & 0,88                 & 0,83                                 \\
                                                     & F-Score   & 0,48             & 0,91                 & 0,83                                 \\ 
\hline
\multirow{4}{0.141\linewidth}{\hspace{0pt}NN}        & TP-Rate   & 0,43             & 0,72                 & 0,67                                 \\
                                                     & FP-Rate   & 0,28             & 0,57                 & 0,52                                 \\
                                                     & Precision & 0,24             & 0,86                 & 0,75                                 \\
                                                     & F-Score   & 0,31             & 0,78                 & 0,70                                 \\ 
\hline
\multirow{4}{0.141\linewidth}{\hspace{0pt}RF}        & TP-Rate   & 0,66             & 0,88                 & 0,84                                 \\
                                                     & FP-Rate   & 0,12             & 0,34                 & 0,30                                 \\
                                                     & Precision & 0,53             & 0,92                 & 0,86                                 \\
                                                     & F-Score   & 0,59             & 0,90                 & 0,85                                 \\ 
\hline
\multirow{4}{0.141\linewidth}{\hspace{0pt}SGD}       & TP-Rate   & 0,34             & 0,74                 & 0,67                                 \\
                                                     & FP-Rate   & 0,56             & 0,67                 & 0,60                                 \\
                                                     & Precision & 0,21             & 0,84                 & 0,73                                 \\
                                                     & F-Score   & 0,26             & 0,79                 & 0,70                                 \\ 
\hline
\multirow{4}{0.141\linewidth}{\hspace{0pt}SVM}       & TP-Rate   & 0,23             & 0,75                 & 0,66                                 \\
                                                     & FP-Rate   & 0,25             & 0,77                 & 0,68                                 \\
                                                     & Precision & 0,16             & 0,82                 & 0,71                                 \\
                                                     & F-Score   & 0,19             & 0,79                 & 0,68                                 \\
\hline
\end{tabular}
}
\end{table}

\subsubsection*{ROC-Kurven und ROC-Bereiche}

Die Interpretation der ROC-Kurven und ROC-Bereiche erfolgt anhand des in \hyperref[roc-def]{Abschnitt 5.2.1} vorgestellten Schemas. Die ROC-Kurven samt der Werte der ROC-Bereiche (repräsentiert durch \glqq AUC\grqq) sind in \autoref{fig:roc-feat} (featurebasiertes Datenset) und \autoref{fig:roc-file} dargestellt. Zu sehen sind jeweils die von den Tools scikit-learn und WEKA ausgegebenen und unveränderten Plots. Die in den Plots des Tools WEKA dargestellten Farbverläufe der Kurven verdeutlichen keine für diesen Zweck relevanten Informationen und können somit ignoriert werden.

\begin{figure}[t]
  \centering
  \subfloat[][J48\\AUC = 0,77]{\includegraphics[width=0.25\linewidth]{images/j48_feat}} 
  \subfloat[][LR\\AUC = 0,62]{\includegraphics[width=0.25\linewidth]{images/lr_feat}}
  \subfloat[][NN\\AUC = 0,61]{\includegraphics[width=0.25\linewidth]{images/nn_feat}}
  \subfloat[][SGD\\AUC = 0,53]{\includegraphics[width=0.25\linewidth]{images/sgd_feat}}
  \qquad
  \subfloat[][KNN\\AUC = 0,73]{\includegraphics[width=0.25\linewidth]{images/knn_feat}}
  \subfloat[][NB\\AUC = 0,80]{\includegraphics[width=0.25\linewidth]{images/nb_feat}}
  \subfloat[][RF\\AUC = 0,84]{\includegraphics[width=0.25\linewidth]{images/rf_feat}} 
  \subfloat[][SVM\\AUC = 0,49]{\includegraphics[width=0.25\linewidth]{images/svm_feat}}
  \caption{ROC-Kurven des featurebasierten Datensets}
\end{figure}

\subsection{Dateibasierter Vergleich}
\label{classic-eval}

Zum besseren Vergleich der Ergebnisse des Datensets mit neuartiger Fokussierung auf Software-Features, wird nicht nur das unter Zuhilfenahme der gleichen Metriken erstellte dateibasierte Datensets hinzugezogen, sondern zusätzlich ein Datenset, dessen Erstellung aus der wissenschaftlichen Literatur entnommen wurde und sich ebenfalls dem gängigen Weg der dateibasierten Fehlervorhersage widmet. Die von Moser et al. vorgestellte Methode umfasst die Berechnung von 17 Prozessmetriken, welche in \autoref{tab:eval-metrics} aufgeführt sind \cite{Moser2008}. Die Grundlage der Berechnungen bildeten die aus den Software-Repositories mittels PyDriller erhaltenen Daten. Zur Berechnung der \texttt{REVISIONS}-Metrik wurden die Commit-Nachrichten, analog zur Identifikation der fehlerbehebenden Commits, auf das Vorhandensein des Schlagwortes \glqq refactor\grqq{} analysiert. Zur Berechnung der Metriken \texttt{AGE} und \texttt{WEIGHTED\_AGE} wurde zudem für jeden Commit das zugehörige Datum der Ausführung abgerufen. Die Berechnung erfolgte entweder direkt mittels SQL-Abrufen oder mithilfe von Python-Skripten. Aufgrund der Unbalanciertheit des Datensets wurde der SMOTE-Algorithmus mit einem Wert von 3000 angewendet.

Zur besseren Vergleichbarkeit dieses Ansatzes, wurden die Metriken für ein weiteres Datenset unter Berücksichtigung des Feature-Aspekts berechnet. Dieses Datenset basiert ebenfalls aus den mit PyDriller erhaltenen Rohdaten und beinhaltet nur jede Dateien, in welchen ein Feature entfernt, hinzugefügt oder verändert wurde. Im weiteren Verlauf des Abschnitts wird dieses Datenset als \glqq vorhandenes Datenset\grqq{} bezeichnet, welches ebenfalls mit dem SMOTE-Algorithmus mit einem Wert von 300 erweitert wurde.

\subsubsection*{Konfusionsmatrizen}

\begin{table}[t]
\centering
\caption{Konfusionsmatrizen der Datensets}
\label{tab:mat-eval}
\resizebox{\linewidth}{!}{%
\begin{tabular}{|>{\hspace{0pt}}p{0.075\linewidth}>{\hspace{0pt}}p{0.231\linewidth}|>{\RaggedLeft\hspace{0pt}}p{0.1\linewidth}>{\RaggedLeft\hspace{0pt}}p{0.135\linewidth}>{\RaggedLeft\hspace{0pt}}p{0.1\linewidth}|>{\RaggedLeft\hspace{0pt}}p{0.102\linewidth}>{\RaggedLeft\hspace{0pt}}p{0.137\linewidth}>{\RaggedLeft\hspace{0pt}}p{0.104\linewidth}|} 
\cline{3-8}
\multicolumn{1}{>{\hspace{0pt}}p{0.075\linewidth}}{}            &                                    & \multicolumn{3}{>{\Centering\hspace{0pt}}p{0.335\linewidth}|}{\textbf{Datenset nach \cite{Moser2008}}} & \multicolumn{3}{>{\Centering\hspace{0pt}}p{0.343\linewidth}|}{\textbf{erweitertes Datenset}}  \\ 
\cline{2-8}
\multicolumn{1}{>{\Centering\hspace{0pt}}p{0.075\linewidth}|}{} & \textbf{Ermittelt -\textgreater{}} & \textbf{defekt} & \textbf{fehlerfrei} & \textbf{Total}                                & \textbf{defekt} & \textbf{fehlerfrei} & \textbf{Total}                                        \\ 
\hline
\multirow{3}{0.075\linewidth}{\hspace{0pt}J48}                   & Realität defekt                    & 11              & 102                 & 113                                           & 15              & 98                  & 113                                                   \\
                                                                & Realität fehlerfrei                & 911             & 20.923              & 21.834                                        & 1.120           & 20.714              & 21.834                                                \\
                                                                & Total                              & 922             & 21.025              & 21.947                                        & 1.135           & 2.0812              & 21.947                                                \\ 
\hline
\multirow{3}{0.075\linewidth}{\hspace{0pt}KNN}                  & Realität defekt                    & 29              & 84                  & 113                                           & 20              & 93                  & 113                                                   \\
                                                                & Realität fehlerfrei                & 5.209           & 16.625              & 21.834                                        & 4.861           & 16.973              & 21.834                                                \\
                                                                & Total                              & 5.238           & 16.709              & 21.947                                        & 4.881           & 17.066              & 21.947                                                \\ 
\hline
\multirow{3}{0.075\linewidth}{\hspace{0pt}LR}                   & Realität defekt                    & 36              & 77                  & 113                                           & 32              & 81                  & 113                                                   \\
                                                                & Realität fehlerfrei                & 2.520           & 19.314              & 21.834                                        & 2.578           & 19.256              & 21.834                                                \\
                                                                & Total                              & 2.556           & 19.391              & 21.947                                        & 2.610           & 19.337              & 21.947                                                \\ 
\hline
\multirow{3}{0.075\linewidth}{\hspace{0pt}NB}                   & Realität defekt                    & 77              & 36                  & 113                                           & 83              & 30                  & 113                                                   \\
                                                                & Realität fehlerfrei                & 18.700          & 3.134               & 21.834                                        & 18.750          & 3.084               & 21.834                                                \\
                                                                & Total                              & 18.777          & 3.170               & 21.947                                        & 18.833          & 3.114               & 21.947                                                \\ 
\hline
\multirow{3}{0.075\linewidth}{\hspace{0pt}NN}                   & Realität defekt                    & 6               & 107                 & 113                                           & 1               & 112                 & 113                                                   \\
                                                                & Realität fehlerfrei                & 4.341           & 17.493              & 21.834                                        & 141             & 21.693              & 21.834                                                \\
                                                                & Total                              & 4.347           & 17.600              & 21.947                                        & 142             & 21.805              & 21.947                                                \\ 
\hline
\multirow{3}{0.075\linewidth}{\hspace{0pt}RF}                   & Realität defekt                    & 7               & 106                 & 113                                           & 4               & 109                 & 113                                                   \\
                                                                & Realität fehlerfrei                & 382             & 21.452              & 21.834                                        & 366             & 21.468              & 21.834                                                \\
                                                                & Total                              & 389             & 21.558              & 21.947                                        & 370             & 21.577              & 21.947                                                \\ 
\hline
\multirow{3}{0.075\linewidth}{\hspace{0pt}SGD}                  & Realität defekt                    & 22              & 91                  & 113                                           & 20              & 93                  & 113                                                   \\
                                                                & Realität fehlerfrei                & 1.260           & 20.574              & 21.834                                        & 1.226           & 20.608              & 21.834                                                \\
                                                                & Total                              & 1.282           & 20.665              & 21.947                                        & 1.246           & 20.701              & 21.947                                                \\ 
\hline
\multirow{3}{0.075\linewidth}{\hspace{0pt}SVM}                  & Realität defekt                    & 22              & 91                  & 113                                           & 21              & 92                  & 113                                                   \\
                                                                & Realität fehlerfrei                & 1.041           & 20.793              & 21.834                                        & 991             & 20.843              & 21.834                                                \\
                                                                & Total                              & 1.063           & 20.884              & 21.947                                        & 1.012           & 20.935              & 21.947                                                \\
\hline
\end{tabular}
}
\end{table}

\subsubsection*{Accuracies}

\begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{images/final_eval}
    \caption{Vergleich der Accuracies der Datensets\label{fig:final-eval}}
\end{figure}

\subsubsection*{Weitere Evaluationsmetriken}

\begin{table}[t]
\centering
\caption{Ergebnisse der Evaluationsmetriken der Datensets}
\label{tab:met-results}
\resizebox{\linewidth}{!}{%
\begin{tabular}{|>{\hspace{0pt}}p{0.087\linewidth}>{\hspace{0pt}}p{0.15\linewidth}|>{\RaggedLeft\hspace{0pt}}p{0.114\linewidth}>{\RaggedLeft\hspace{0pt}}p{0.156\linewidth}>{\RaggedLeft\hspace{0pt}}p{0.102\linewidth}|>{\RaggedLeft\hspace{0pt}}p{0.114\linewidth}>{\RaggedLeft\hspace{0pt}}p{0.158\linewidth}>{\RaggedLeft\hspace{0pt}}p{0.104\linewidth}|} 
\cline{3-8}
\multicolumn{1}{>{\hspace{0pt}}p{0.087\linewidth}}{} &           & \multicolumn{3}{>{\Centering\hspace{0pt}}p{0.372\linewidth}|}{\textbf{Datenset nach \cite{Moser2008}} } & \multicolumn{3}{>{\Centering\hspace{0pt}}p{0.376\linewidth}|}{\textbf{erweitertes Datenset} }  \\ 
\cline{3-8}
\multicolumn{1}{>{\hspace{0pt}}p{0.087\linewidth}}{} &           & \textbf{defekt}  & \textbf{fehlerfrei}  & \textbf{gew.}\par{}\textbf{Mittel}            & \textbf{defekt}  & \textbf{fehlerfrei}  & \textbf{gew.}\par{}\textbf{Mittel}                   \\ 
\hline
\multirow{4}{0.087\linewidth}{\hspace{0pt}J48}       & TP-Rate   & 0,10             & 0,96                 & 0,95                                          & 0,13             & 0,95                 & 0,95                                                 \\
                                                     & FP-Rate   & 0,04             & 0,90                 & 0,90                                          & 0,05             & 0,87                 & 0,86                                                 \\
                                                     & Precision & 0,01             & 1,00                 & 0,99                                          & 0,01             & 1,00                 & 0,99                                                 \\
                                                     & F-Score   & 0,02             & 0,98                 & 0,97                                          & 0,02             & 0,97                 & 0,97                                                 \\ 
\hline
\multirow{4}{0.087\linewidth}{\hspace{0pt}KNN}       & TP-Rate   & 0,26             & 0,76                 & 0,76                                          & 0,18             & 0,78                 & 0,77                                                 \\
                                                     & FP-Rate   & 0,24             & 0,74                 & 0,74                                          & 0,22             & 0,82                 & 0,82                                                 \\
                                                     & Precision & 0,01             & 1,00                 & 0,99                                          & 0,00             & 1,00                 & 0,99                                                 \\
                                                     & F-Score   & 0,01             & 0,86                 & 0,86                                          & 0,01             & 0,87                 & 0,87                                                 \\ 
\hline
\multirow{4}{0.087\linewidth}{\hspace{0pt}LR}        & TP-Rate   & 0,32             & 0,89                 & 0,88                                          & 0,28             & 0,88                 & 0,88                                                 \\
                                                     & FP-Rate   & 0,12             & 0,68                 & 0,68                                          & 0,12             & 0,72                 & 0,71                                                 \\
                                                     & Precision & 0,01             & 1,00                 & 0,99                                          & 0,01             & 1,00                 & 0,99                                                 \\
                                                     & F-Score   & 0,03             & 0,94                 & 0,93                                          & 0,02             & 0,94                 & 0,93                                                 \\ 
\hline
\multirow{4}{0.087\linewidth}{\hspace{0pt}NB}        & TP-Rate   & 0,68             & 0,14                 & 0,15                                          & 0,74             & 0,14                 & 0,14                                                 \\
                                                     & FP-Rate   & 0,86             & 0,32                 & 0,32                                          & 0,86             & 0,27                 & 0,27                                                 \\
                                                     & Precision & 0,00             & 0,99                 & 0,98                                          & 0,00             & 0,99                 & 0,99                                                 \\
                                                     & F-Score   & 0,01             & 0,25                 & 0,25                                          & 0,01             & 0,25                 & 0,25                                                 \\ 
\hline
\multirow{4}{0.087\linewidth}{\hspace{0pt}NN}        & TP-Rate   & 0,05             & 0,80                 & 0,80                                          & 0,01             & 0,99                 & 0,99                                                 \\
                                                     & FP-Rate   & 0,20             & 0,95                 & 0,94                                          & 0,01             & 0,99                 & 0,99                                                 \\
                                                     & Precision & 0,00             & 0,99                 & 0,99                                          & 0,01             & 1,00                 & 0,99                                                 \\
                                                     & F-Score   & 0,00             & 0,89                 & 0,88                                          & 0,01             & 0,99                 & 0,99                                                 \\ 
\hline
\multirow{4}{0.087\linewidth}{\hspace{0pt}RF}        & TP-Rate   & 0,06             & 0,98                 & 0,98                                          & 0,04             & 0,98                 & 0,98                                                 \\
                                                     & FP-Rate   & 0,02             & 0,94                 & 0,93                                          & 0,02             & 0,97                 & 0,96                                                 \\
                                                     & Precision & 0,02             & 1,00                 & 0,99                                          & 0,01             & 1,00                 & 0,99                                                 \\
                                                     & F-Score   & 0,03             & 0,90                 & 0,98                                          & 0,02             & 0,99                 & 0,98                                                 \\ 
\hline
\multirow{4}{0.087\linewidth}{\hspace{0pt}SGD}       & TP-Rate   & 0,20             & 0,94                 & 0,94                                          & 0,18             & 0,94                 & 0,94                                                 \\
                                                     & FP-Rate   & 0,06             & 0,81                 & 0,80                                          & 0,06             & 0,82                 & 0,82                                                 \\
                                                     & Precision & 0,02             & 1,00                 & 0,99                                          & 0,02             & 1,00                 & 0,99                                                 \\
                                                     & F-Score   & 0,03             & 0,97                 & 0,96                                          & 0,03             & 0,97                 & 0,96                                                 \\ 
\hline
\multirow{4}{0.087\linewidth}{\hspace{0pt}SVM}       & TP-Rate   & 0,20             & 0,95                 & 0,95                                          & 0,19             & 1,00                 & 0,95                                                 \\
                                                     & FP-Rate   & 0,05             & 0,81                 & 0,80                                          & 0,05             & 0,81                 & 0,81                                                 \\
                                                     & Precision & 0,02             & 1,00                 & 0,99                                          & 0,02             & 1,00                 & 0,99                                                 \\
                                                     & F-Score   & 0,04             & 0,97                 & 0,97                                          & 0,04             & 0,98                 & 0,97                                                 \\
\hline
\end{tabular}
}
\end{table}

\subsubsection*{ROC-Kurven und ROC-Bereiche}

\begin{figure}[t]
  \centering
  \subfloat[][J48 n. \cite{Moser2008}\\AUC = 0,61]{\includegraphics[width=0.25\linewidth]{images/j48_eval}} 
  \subfloat[][J48 e. D.\\AUC = 0,61]{\includegraphics[width=0.25\linewidth]{images/j48_eval_feat}}
  \subfloat[][NN n. \cite{Moser2008}\\AUC = 0,37]{\includegraphics[width=0.25\linewidth]{images/nn_eval}}
  \subfloat[][NN e. D.\\AUC = 0,54]{\includegraphics[width=0.25\linewidth]{images/nn_eval_feat}}
  \qquad
  \subfloat[][KNN n. \cite{Moser2008}\\AUC = 0,55]{\includegraphics[width=0.25\linewidth]{images/knn_eval}}
  \subfloat[][KNN e. D.\\AUC = 0,52]{\includegraphics[width=0.25\linewidth]{images/knn_eval_feat}}
  \subfloat[][RF n. \cite{Moser2008}\\AUC = 0,71]{\includegraphics[width=0.25\linewidth]{images/rf_eval}} 
  \subfloat[][RF e. D.\\AUC = 0,71]{\includegraphics[width=0.25\linewidth]{images/rf_eval_feat}} 
  \qquad
  \subfloat[][LR n. \cite{Moser2008}\\AUC = 0,65]{\includegraphics[width=0.25\linewidth]{images/lr_eval}}
  \subfloat[][LR e. D.\\AUC = 0,62]{\includegraphics[width=0.25\linewidth]{images/lr_eval_feat}}
  \subfloat[][SGD n. \cite{Moser2008}\\AUC = 0,57]{\includegraphics[width=0.25\linewidth]{images/sgd_eval}}
  \subfloat[][SGD e. D.\\AUC = 0,56]{\includegraphics[width=0.25\linewidth]{images/sgd_eval_feat}}
  \qquad
  \subfloat[][NB n. \cite{Moser2008}\\AUC = 0,48]{\includegraphics[width=0.25\linewidth]{images/nb_eval}}
  \subfloat[][NB e. D.\\AUC = 0,47]{\includegraphics[width=0.25\linewidth]{images/nb_eval_feat}}
  \subfloat[][SVM n. \cite{Moser2008}\\AUC = 0,57]{\includegraphics[width=0.25\linewidth]{images/svm_eval}}
  \subfloat[][SVM e. D.\\AUC = 0,57]{\includegraphics[width=0.25\linewidth]{images/svm_eval_feat}}
  \caption{ROC-Kurven der Datensets\\e.D. = erweitertes Datenset}
\end{figure}

\fbox{\parbox{\linewidth}{RQ3c: WELCHE VOR- UND NACHTEILE BESITZT EIN KLASSIFIKATOR?\medskip\\
Hier soll mal so viel Text stehen, damit der ganze Text nicht nur in einer Zeile steht sondern in mindestens zwei oder mehr Zeilen, denn andernfalls werden wir nicht sehen können ob der Rahmen nur um die erste Zeile geht, oder wie wir wollen sich um den ganzen Absatz zieht.}}

\fbox{\parbox{\linewidth}{RQ3d: WIE LASSEN SICH DIE KLASSIFIKATOREN MIT WEITEREN VORHERSAGETECHNIKEN, DIE KEINE FEATURES NUTZEN, VERGLEICHEN?\medskip\\
Es wurde auf eine Methode zur Erstellung eines dateibasierten Datensets aus der wissenschaftlichen Literatur zurückgegriffen \cite{Moser2008}. Dieses Datenset basiert auf den mittels PyDriller abgerufenen Daten und umfasst 17 Attribute. Zum besseren Vergleich wurde ein weiteres Datenset erstellt, welches nur jene Dateien umfasst, in denen sich Featurecode befindet.}}

\fbox{\parbox{\linewidth}{RQ3e: WIE BEEINFLUSST DIE VERWENDUNG VON FEATUREBASIERTEN METRIKEN DIE FEHLERVORHERSAGE?\medskip\\
Hier soll mal so viel Text stehen, damit der ganze Text nicht nur in einer Zeile steht sondern in mindestens zwei oder mehr Zeilen, denn andernfalls werden wir nicht sehen können ob der Rahmen nur um die erste Zeile geht, oder wie wir wollen sich um den ganzen Absatz zieht.}}


\cleardoublepage
